
import streamlit as st
import cv2
import os
from PIL import Image
import numpy as np


from detector_pessoas_pose import detectar_pessoas_e_poses
from detector_faces import detectar_faces
from expressao_boca_face_mesh import analisar_expressoes_faciais
from analise_pose_gestos import analisar_gesticulacao
from direcao_olhar import analisar_direcao_olhar
from classificador_social import classificar_papeis_sociais
from app_teste import desenhar_resultados 

st.set_page_config(
    page_title="Analisador de Intera√ß√£o Social",
    page_icon="üë•",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Fun√ß√µes Auxiliares ---
def run_pipeline(image_path):
    """Executa o pipeline completo e retorna os resultados e a imagem final."""
    # Etapa 1: Detec√ß√£o de Pessoas e Pose
    deteccoes_pose = detectar_pessoas_e_poses(image_path)
    if not deteccoes_pose:
        return None, None # Retorna None se ningu√©m for detectado

    # Etapas subsequentes
    deteccoes_face = detectar_faces(image_path, deteccoes_pose)
    deteccoes_expressoes = analisar_expressoes_faciais(image_path, deteccoes_face)
    deteccoes_gestos = analisar_gesticulacao(deteccoes_expressoes)
    deteccoes_olhar = analisar_direcao_olhar(deteccoes_gestos)
    resultado_final = classificar_papeis_sociais(deteccoes_olhar)

    # Desenha o resultado na imagem
    img = cv2.imread(image_path)
    img_resultado = desenhar_resultados(img, resultado_final)
    
    return resultado_final, img_resultado

# --- Interface Principal ---
st.title("üë• Analisador de Intera√ß√£o Social em Imagens")
st.markdown("""
Esta aplica√ß√£o utiliza um pipeline de Vis√£o Computacional para detectar pessoas em uma imagem e classific√°-las como **Falando** ou **Ouvindo**.

O modelo analisa m√∫ltiplos fatores:
- **Pose Corporal e Gestos:** Para identificar gesticula√ß√£o ativa.
- **Express√µes Faciais:** Foco na abertura da boca como principal indicador de fala.
- **Dire√ß√£o do Olhar:** Para inferir para quem uma pessoa est√° prestando aten√ß√£o.

**Instru√ß√µes:**
1.  Fa√ßa o upload de uma imagem no painel √† esquerda.
2.  Aguarde a an√°lise ser conclu√≠da.
3.  Veja o resultado na tela!
""")

# --- Barra Lateral (Sidebar) ---
st.sidebar.header("‚öôÔ∏è Configura√ß√µes")
uploaded_file = st.sidebar.file_uploader(
    "Escolha uma imagem (JPG, PNG)", 
    type=['jpg', 'jpeg', 'png']
)

st.sidebar.markdown("--- ")
st.sidebar.info("Projeto desenvolvido para demonstrar um pipeline de an√°lise de comportamento social.")

# --- L√≥gica Principal da Aplica√ß√£o ---
if uploaded_file is not None:
    
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    opencv_image = cv2.imdecode(file_bytes, 1)
    
    temp_dir = "."
    temp_image_path = os.path.join(temp_dir, "temp_uploaded_image.jpg")
    cv2.imwrite(temp_image_path, opencv_image)

    # Exibe a imagem original
    st.header("üñºÔ∏è Imagem Original")
    st.image(opencv_image, channels="BGR", caption="Imagem enviada pelo usu√°rio.", use_column_width=True)

    st.markdown("--- ")

    # Adiciona um bot√£o para iniciar a an√°lise
    if st.button("üöÄ Iniciar An√°lise Agora", use_container_width=True):
        # Executa o pipeline
        with st.spinner('üß† Analisando a imagem... Isso pode levar alguns segundos... '):
            resultados_json, imagem_processada = run_pipeline(temp_image_path)

        if resultados_json is None:
            st.warning("‚ö†Ô∏è Nenhuma pessoa foi detectada na imagem. Tente outra imagem.")
        else:
            st.success("‚úÖ An√°lise conclu√≠da com sucesso!")
            st.balloons()

            # --- Layout de Duas Colunas para o Resultado ---
            col1, col2 = st.columns([2, 1]) 

            with col1:
                st.header("üìä Resultado da An√°lise")
                st.image(imagem_processada, channels="BGR", caption="Imagem com os pap√©is sociais identificados.", use_column_width=True)

            with col2:
                st.header("üìñ Legenda e Detalhes")
                
                st.markdown("""
                <style>
                .legend-color-box {
                    width: 20px;
                    height: 20px;
                    display: inline-block;
                    border: 1px solid #ccc;
                    margin-right: 10px;
                    vertical-align: middle;
                }
                .legend-container {
                    margin-bottom: 20px;
                }
                </style>
                
                <div class="legend-container">
                    <div>
                        <span class="legend-color-box" style="background-color: #00FF00;"></span>
                        <strong>Falando</strong>
                    </div>
                    <div style="margin-top: 10px;">
                        <span class="legend-color-box" style="background-color: #FFA500;"></span>
                        <strong>Ouvindo</strong>
                    </div>
                </div>
                """, unsafe_allow_html=True)

                # Resumo do Workflow
                st.markdown("---")
                st.subheader("Como o modelo funciona?")
                st.markdown("""
                O resultado √© gerado por um pipeline de 6 etapas:
                1.  **Detec√ß√£o de Pessoas e Pose:** Encontra pessoas e seus esqueletos (`YOLOv8`).
                2.  **Detec√ß√£o de Rosto:** Localiza o rosto de cada pessoa.
                3.  **An√°lise de Express√£o:** Verifica se a boca est√° aberta (`MediaPipe`).
                4.  **An√°lise de Gestos:** Avalia se as m√£os est√£o gesticulando.
                5.  **Dire√ß√£o do Olhar:** Estima para quem a pessoa est√° olhando.
                6.  **Classifica√ß√£o Final:** Uma l√≥gica combina todas as pistas para definir o papel social.
                """)

                # Expander para mostrar os dados JSON
                with st.expander("üìÑ Ver detalhes t√©cnicos (JSON)"):
                    st.json(resultados_json)

else:
    st.info("Aguardando o upload de uma imagem para iniciar a an√°lise.")

